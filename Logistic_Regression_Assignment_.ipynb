{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#LOGISTIC REGRESSION"
      ],
      "metadata": {
        "id": "6k2BX9x5iI4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 1: What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "\n",
        "- Logistic Regression is a supervised machine learning algorithm used for classification problems, where the output (dependent variable) is categorical â€” for example, predicting whether an email is spam or not spam, or whether a patient has a disease or not.\n",
        "\n",
        "- Logistic Regression Works:\n",
        "\n",
        "   - Instead of predicting continuous values like Linear Regression, it predicts the probability that a data point belongs to a particular class.\n",
        "\n",
        "   - It uses the logistic (sigmoid) function to map predicted values between 0 and 1, which represent probabilities.\n",
        "\n",
        "- Differences:-\n",
        "\n",
        "1. In linear regression the type of problem is regression and in logistic it is classification.\n",
        "\n",
        "2. In linear regression the output is any real number but in logistic the output is probability between 0 and 1.\n",
        "\n",
        "3. Goal of Linear regression is MSE (Minimize mean squared error) and goal of logistic is maximize likelihood.\n",
        "\n",
        "4. Example of linear regression is predicting house prices whereas example of logistic regression is predicting if a customer will buy the product or not.\n",
        "\n",
        "\n",
        "\n",
        "#Question 2: Explain the role of the Sigmoid function in Logistic Regression.\n",
        "\n",
        "- The Sigmoid function plays a central role in Logistic Regression because it converts the linear output of the model into a probability value between 0 and 1, making classification possible.\n",
        "\n",
        "Formula of the Sigmoid Function:\n",
        "\n",
        "     z = 1/1+e^-z\n",
        "\n",
        "where\n",
        "\n",
        "z = b0 + b1x1 + b2x2 + ----- bnxn\n",
        "\n",
        "- Role in Logistic Regression:\n",
        "\n",
        "1. Transforms Linear Output to Probability:\n",
        "    - The raw output z from the linear equation can be any real number (positive or negative).\n",
        "     - The Sigmoid function compresses it into a value between 0 and 1, which can be interpreted as a probability.\n",
        "\n",
        "2. It helps in classification:\n",
        " - if P(Y=1) > 0.5, predicts class 1\n",
        " - if P(Y=1) <= 0.5, predicts class 0   \n",
        "\n",
        "3. Ensures Smooth Gradient for Optimization:\n",
        "     - The sigmoid curve is smooth and differentiable, allowing gradient descent to optimize the model parameters effectively.\n",
        "\n",
        "4. Probability Interpretation\n",
        "     - The Sigmoid function transforms any real-valued number into a value between 0 and 1, which can be interpreted as the probability of the sample belonging to the positive class.\n",
        "\n",
        "5. Non-linearity Introduction\n",
        "     - Even though Logistic Regression is based on a linear equation, the Sigmoid function adds non-linearity, enabling the model to handle relationships where the dependent variable changes sharply around a threshold.\n",
        "\n",
        "\n",
        "#Question 3: What is Regularization in Logistic Regression and why is it needed?\n",
        "\n",
        "\n",
        "- Regularization in Logistic Regression is a technique used to prevent overfitting by adding a penalty term to the modelâ€™s cost (loss) function.\n",
        "\n",
        "- It ensures that the model does not become too complex or depend too heavily on any one feature, which helps it generalize better on new, unseen data.\n",
        "\n",
        "- Why Regularization is Needed:\n",
        "\n",
        "1. Prevents Overfitting:\n",
        "   - When a model fits the training data too perfectly, it may perform poorly on test data. Regularization discourages overly large coefficient values, reducing overfitting.\n",
        "\n",
        "2. Controls Model Complexity:\n",
        "   - By penalizing large weights, regularization keeps the model simple and more interpretable.\n",
        "\n",
        "3. Improves Generalization:\n",
        "   - A regularized model performs better on unseen data because it focuses on important patterns rather than noise.\n",
        "\n",
        "4. Handles Multicollinearity:\n",
        "   - If features are highly correlated, regularization helps by reducing their coefficients, making the model more stable.\n",
        "\n",
        "- Types of Regularization in Logistic Regression:   \n",
        "\n",
        "1. L1 Regularization (Lasso)\n",
        "   - Effect = w_i\n",
        "\n",
        "2. L2 Regularization (Ridge)\n",
        "   - Effect = Reduces the magnitude of all coefficients but rarely makes them zero; helps smoothly shrink weights.\n",
        "\n",
        "\n",
        "#Question 4: What are some common evaluation metrics for classification models, and why are they important?      \n",
        "\n",
        "\n",
        "- Evaluation metrics for classification models are used to measure how well the model predicts the correct categories.\n",
        "\n",
        "- They are important because they help us understand a modelâ€™s accuracy, reliability, and usefulness in real-world decision-making â€” especially when data is imbalanced or when certain types of errors (like false positives) are more serious than others.\n",
        "\n",
        "- Why These Metrics Are Important:\n",
        "\n",
        "1. Provide deeper insights than accuracy alone.\n",
        "\n",
        "2. Help select the best model for specific use cases (e.g., medical, finance, spam detection).\n",
        "\n",
        "3. Show trade-offs between false positives and false negatives.\n",
        "\n",
        "4. Assist in tuning thresholds to optimize model performance.\n",
        "\n",
        "- Common Evaluation Metrics for Classification Models:-\n",
        "\n",
        "1. Accuracy\n",
        "\n",
        "   - Meaning: Measures the percentage of total correct predictions.\n",
        "\n",
        "   - Importance: Simple and easy to interpret, but works best when classes are balanced.\n",
        "\n",
        "2. Precision\n",
        "\n",
        "   - Meaning: Out of all instances predicted as positive, how many are actually positive.\n",
        "\n",
        "   - Importance: Useful when false positives are costly â€” for example, marking a normal email as spam.\n",
        "\n",
        "3. Recall\n",
        "\n",
        "    - Meaning: Out of all actual positive cases, how many the model correctly identified.\n",
        "\n",
        "     - Importance: Important when missing positive cases is risky â€” for example, detecting diseases or fraud.\n",
        "\n",
        "4. F1 Score\n",
        "\n",
        "    - Meaning: It is the harmonic mean of Precision and Recall.\n",
        "\n",
        "    - Importance: Balances Precision and Recall; useful when data is imbalanced.\n",
        "\n",
        "5. 5. Confusion Matrix\n",
        "\n",
        "    - Meaning: A table showing counts of True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN).\n",
        "\n",
        "    - Importance: Gives a complete picture of the modelâ€™s performance, showing where it makes mistakes.   \n",
        "\n",
        "\n",
        "#Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame, splits into train/test sets, trains a Logistic Regression model, and prints its accuracy. (Use Dataset from sklearn package)\n",
        "    \n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "1FuXnobDicC8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvXs68HsiESe",
        "outputId": "5774c838-c95d-412c-8bcc-06da9e34a1b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Preview:\n",
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                5.1               3.5                1.4               0.2   \n",
            "1                4.9               3.0                1.4               0.2   \n",
            "2                4.7               3.2                1.3               0.2   \n",
            "3                4.6               3.1                1.5               0.2   \n",
            "4                5.0               3.6                1.4               0.2   \n",
            "\n",
            "   target  \n",
            "0       0  \n",
            "1       0  \n",
            "2       0  \n",
            "3       0  \n",
            "4       0  \n",
            "\n",
            "Model Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "print(\"Dataset Preview:\")\n",
        "print(df.head())\n",
        "\n",
        "X = df[iris.feature_names]\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nModel Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 6: Write a Python program to train a Logistic Regression model using L2 regularization (Ridge) and print the model coefficients and accuracy. (Use Dataset from sklearn package)"
      ],
      "metadata": {
        "id": "Jj1TyX6OL7PF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data = load_breast_cancer()\n",
        "\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "X = df[data.feature_names]\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"ðŸ”¹ Logistic Regression with L2 Regularization (Ridge)\")\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"Model Coefficients:\\n\", model.coef_)\n",
        "print(\"\\nModel Intercept:\\n\", model.intercept_)\n",
        "print(f\"\\nModel Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyJf61GYI5XO",
        "outputId": "e660f932-3176-415d-b834-1eb1e28b7649"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¹ Logistic Regression with L2 Regularization (Ridge)\n",
            "---------------------------------------------------\n",
            "Model Coefficients:\n",
            " [[ 2.09981182  0.13248576 -0.10346836 -0.00255646 -0.17024348 -0.37984365\n",
            "  -0.69120719 -0.4081069  -0.23506963 -0.02356426 -0.0854046   1.12246945\n",
            "  -0.32575716 -0.06519356 -0.02371113  0.05960156  0.00452206 -0.04277587\n",
            "  -0.04148042  0.01425051  0.96630267 -0.37712622 -0.05858253 -0.02395975\n",
            "  -0.31765956 -1.00443507 -1.57134711 -0.69351401 -0.84095566 -0.09308282]]\n",
            "\n",
            "Model Intercept:\n",
            " [2.13128402]\n",
            "\n",
            "Model Accuracy: 95.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 7: Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr' and print the classification report. (Use Dataset from sklearn package)\n"
      ],
      "metadata": {
        "id": "7VMEcQDxNbzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "X = df[iris.feature_names]\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=500)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"ðŸ”¹ Logistic Regression (One-vs-Rest) Classification Report:\")\n",
        "print(\"-----------------------------------------------------------\")\n",
        "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "en66zDejMi6F",
        "outputId": "50dafaee-4d31-4773-8cb0-793ac52cf5dc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¹ Logistic Regression (One-vs-Rest) Classification Report:\n",
            "-----------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      0.89      0.94         9\n",
            "   virginica       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.96      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 8: Write a Python program to apply GridSearchCV to tune C and penalty hyperparameters for Logistic Regression and print the best parameters and validation accuracy. (Use Dataset from sklearn package)\n"
      ],
      "metadata": {
        "id": "Tyu4vOJdOGhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "logreg = LogisticRegression(solver='liblinear', multi_class='ovr', max_iter=200)\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "y_pred = grid_search.best_estimator_.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Validation Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8FfTVppOGCq",
        "outputId": "04ff4308-bb97-4d8c-96a8-3f40c9516426"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'C': 10, 'penalty': 'l1'}\n",
            "Validation Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 9: Write a Python program to standardize the features before training Logistic Regression and compare the model's accuracy with and without scaling(Use Dataset from sklearn package)\n"
      ],
      "metadata": {
        "id": "mo_xnFF9V_JV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "model_no_scaling = LogisticRegression(max_iter=200)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "print(\"Accuracy without scaling:\", accuracy_no_scaling)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression(max_iter=200)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "print(\"Accuracy with scaling:\", accuracy_scaled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0aaa-_zN8H0",
        "outputId": "1ef77787-172b-43f9-84a5-500c461cd008"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 1.0\n",
            "Accuracy with scaling: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 10: Imagine you are working at an e-commerce company that wants to predict which customers will respond to a marketing campaign. Given an imbalanced dataset (only 5% of customers respond), describe the approach youâ€™d take to build a Logistic Regression model â€” including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business use case.\n"
      ],
      "metadata": {
        "id": "VLR6HK8CXHSA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Understand the Problem\n",
        "\n",
        "   - Target: Predict whether a customer will respond (1) or not (0) to a marketing campaign.\n",
        "\n",
        "   - Issue: Only 5% of customers respond â†’ highly imbalanced dataset.\n",
        "\n",
        "   - Goal: Maximize true positives (catch responders) while controlling false positives.\n",
        "\n",
        "2. Data Handling\n",
        "\n",
        "   - Check for missing values and handle them (mean/median for numeric, mode for categorical).\n",
        "\n",
        "   - Feature selection/engineering:\n",
        "\n",
        "   - Encode categorical variables (One-Hot or Ordinal Encoding).\n",
        "\n",
        "   - Create meaningful features (e.g., recency, frequency, monetary value).\n",
        "\n",
        "   - Split the dataset into training and test sets using stratification to preserve class distribution.\n",
        "\n",
        "3. Feature Scaling\n",
        "\n",
        "   - Logistic Regression benefits from scaled features, especially if using regularization.\n",
        "\n",
        "   - Use StandardScaler or MinMaxScaler\n",
        "\n",
        "4. Handling Class Imbalance\n",
        "\n",
        "   - With only 5% responders, a naive model predicts all zeros â†’ 95% accuracy but useless.\n",
        "\n",
        "   Strategies:\n",
        "\n",
        "      - Class weighting in Logistic Regression.\n",
        "\n",
        "   Resampling:\n",
        "\n",
        "     - Oversample minority class: e.g., SMOTE (imblearn.over_sampling.SMOTE).\n",
        "\n",
        "     - Undersample majority class (careful not to lose data).\n",
        "\n",
        "5. Hyperparameter Tuning\n",
        "\n",
        "   - Key parameters for Logistic Regression:\n",
        "\n",
        "   - C: Inverse of regularization strength.\n",
        "\n",
        "   - penalty: 'l1', 'l2', or 'elasticnet'.\n",
        "\n",
        "   - Use GridSearchCV with cross-validation.\n",
        "\n",
        "\n",
        "\n",
        "   "
      ],
      "metadata": {
        "id": "wk0RPzniY5Pt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rXv1JuJiXF36"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}